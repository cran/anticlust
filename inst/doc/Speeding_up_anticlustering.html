<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Martin Papenberg" />


<title>Speeding up anticlustering</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>
<script>// Hide empty <a> tag within highlighted CodeBlock for screen reader accessibility (see https://github.com/jgm/pandoc/issues/6352#issuecomment-626106786) -->
// v0.0.1
// Written by JooYoung Seo (jooyoung@psu.edu) and Atsushi Yasumoto on June 1st, 2020.

document.addEventListener('DOMContentLoaded', function() {
  const codeList = document.getElementsByClassName("sourceCode");
  for (var i = 0; i < codeList.length; i++) {
    var linkList = codeList[i].getElementsByTagName('a');
    for (var j = 0; j < linkList.length; j++) {
      if (linkList[j].innerHTML === "") {
        linkList[j].setAttribute('aria-hidden', 'true');
      }
    }
  }
});
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>



<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Speeding up anticlustering</h1>
<h4 class="author">Martin Papenberg</h4>



<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true"></a><span class="kw">library</span>(anticlust)</span></code></pre></div>
<p>This vignette documents various ways by which the speed of the anticlustering method implemented in the <code>anticlust</code> package can be adjusted. Speedup is particularly useful for large data sets when the default anticlustering algorithm becomes too slow. A fast method may also be desirable for testing purposes, even if the final anticlustering is based on a slower method.</p>
<div id="the-exchange-algorithm" class="section level2">
<h2>The exchange algorithm</h2>
<p>The default anticlustering algorithm works by exchanging data points between clusters in such a way that exchanges improve the anticlustering objective as much as possible. Details on the exchange method may also be found in Papenberg and Klau (2021; <a href="https://doi.org/10.1037/met0000301" class="uri">https://doi.org/10.1037/met0000301</a>), Papenberg (2023; <a href="https://doi.org/10.1111/bmsp.12315" class="uri">https://doi.org/10.1111/bmsp.12315</a>), or the <code>anticlust</code> documentation (<code>?anticlustering</code>). Basically, running more exchanges tends to improve the results, but the improvements are diminishing with many repetitions—especially for large data sets. So, to speed up <code>anticlustering()</code>, we can reduce the number of exchanges. Here we will learn how to do that. However, first we learn how to slow down anticlustering. Slowing down can lead to better results and is recommended if you have the time.</p>
<div id="slowing-down" class="section level3">
<h3>Slowing down</h3>
<p>The default exchange algorithm (<code>anticlustering(..., method = &quot;exchange&quot;)</code>) iterates through all input elements and attempts to improve the anticlustering by swapping each input element with a element that is currently assigned to a different cluster. No swap is conducted if an element cannot be swapped in such a way that the anticlustering objective is improved. The process stops after all possible exchanges have been evaluated for each element. When the number of input elements is <span class="math inline">\(N\)</span>, this process leads to approximately <span class="math inline">\(N^2\)</span>—or <span class="math inline">\(O(N^2)\)</span>—attempted exchanges, because each element is swapped with all elements that are currently assigned to a different cluster. To give a concrete example, when having <span class="math inline">\(N = 100\)</span> data points and <span class="math inline">\(K = 4\)</span> equal-sized groups, 75 swaps are evaluated for each element and the best swap is realized. This leads to 100 * 75 = 7500 exchanges that have to be conducted during the entire exchange algorithm, and for each exchange the objective function has to be re-evaluated. This is less exchanges than <span class="math inline">\(N^2 = 100^2 = 10000\)</span> because we skip exchanges with the 25 elements that are currently in the same cluster (including itself). However, according to the <a href="https://en.wikipedia.org/wiki/Big_O_notation">Big O notation</a>, we would still classify the number of exchanges as <span class="math inline">\(O(N^2)\)</span>, independent of the number of groups. Thus, the total theoretical run time of the exchange method is <span class="math inline">\(O(N^2)\)</span> multiplied with the effort needed to compute an anticlustering objective.</p>
<p>The results of the exchange method can be improved by not stopping after a single iteration through the data set; instead we may repeat the process until no single exchange is able to further improve the anticlustering objective, i.e., until a local maximum is found. This happens if we use <code>anticlustering(..., method = &quot;local-maximum&quot;)</code>. This method corresponds to the algorithm “LCW” in Weitz and Lakshminarayanan (1998). Using the local maximum method leads to more exchanges and thus to longer running time, but also better results than the default exchange method.</p>
<p>Let’s compare the two exchange methods with regard to their running time, using the iris data set, which contains 150 elements.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true"></a></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true"></a>K &lt;-<span class="st"> </span><span class="dv">3</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(iris[, <span class="dv">-5</span>], <span class="dt">K =</span> K, <span class="dt">method =</span> <span class="st">&quot;exchange&quot;</span>))</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true"></a><span class="co">#&gt;       0.007       0.000       0.008</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(iris[, <span class="dv">-5</span>], <span class="dt">K =</span> K, <span class="dt">method =</span> <span class="st">&quot;local-maximum&quot;</span>))</span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true"></a><span class="co">#&gt;       0.038       0.000       0.039</span></span></code></pre></div>
<p>Depending on how many iterations are needed, the default exchange method can be much faster than the local maximum method. Generally I would recommend to use <code>method = &quot;local-maximum&quot;</code> for better results, but if speed is an issue, stick with the default.</p>
<p>To slow down even more: The exchange process may be restarted several times, each time using a different initial grouping of the elements. This is accomplished when specifying the <code>repetitions</code> argument, which defaults to 1 repetition of the exchange / local maximum algorithm. Thus, for better results, we may increase the number of repetitions:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true"></a></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true"></a>K &lt;-<span class="st"> </span><span class="dv">3</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(iris[, <span class="dv">-5</span>], <span class="dt">K =</span> K, <span class="dt">method =</span> <span class="st">&quot;exchange&quot;</span>))</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true"></a><span class="co">#&gt;       0.008       0.000       0.008</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(iris[, <span class="dv">-5</span>], <span class="dt">K =</span> K, <span class="dt">method =</span> <span class="st">&quot;local-maximum&quot;</span>))</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true"></a><span class="co">#&gt;       0.034       0.000       0.034</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(iris[, <span class="dv">-5</span>], <span class="dt">K =</span> K, <span class="dt">method =</span> <span class="st">&quot;local-maximum&quot;</span>, <span class="dt">repetitions =</span> <span class="dv">10</span>))</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true"></a><span class="co">#&gt;       0.344       0.004       0.348</span></span></code></pre></div>
<p>In this case, sticking with the default leads to run times that are much much faster. Still, if your data set is not too large, using several repetitions may be useful (but you can judge yourself via the results). The good news is that fewer exchanges may be enough in large data sets: anticlustering generally becomes easier with more data.</p>
</div>
<div id="getting-fast-using-fewer-exchange-partners" class="section level3">
<h3>Getting fast: Using fewer exchange partners</h3>
<p>If the default exchange method is not fast enough for your taste, it is possible to use fewer exchange partners during the anticlustering process. By default, the exchange method evaluates each possible exchange with all elements that are currently assigned to a different cluster, leading to <span class="math inline">\(O(N^2)\)</span> exchanges. If we only use a fixed number of exchange partners per element, we can reduce the number of exchanges to <span class="math inline">\(O(N)\)</span>, corresponding to a gain of an order of magnitude in terms of run time. Using fewer exchange partners for each element may decrease the quality of the results, and is generally only recommended for (very) large data sets. But the run time will be considerably faster.</p>
<p>One way of doing using fewer exchange partners is by including “preclustering” restrictions (see <code>?anticlustering</code>). When setting <code>preclustering = TRUE</code>, the optimization restricts the number of exchange partners to <code>K - 1</code> (very similar) elements. Note that the preclustering algorithm itself has <span class="math inline">\(O(N^2)\)</span> run time, which has to be performed prior to the anticlustering algorithm. Thus, we have to use a larger data set to see the improvement in running time:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true"></a>M &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true"></a>K &lt;-<span class="st"> </span><span class="dv">3</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true"></a>data &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(N<span class="op">*</span>M), <span class="dt">ncol =</span> M)</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> K))</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true"></a><span class="co">#&gt;       4.279       0.000       4.279</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> K, <span class="dt">preclustering =</span> <span class="ot">TRUE</span>))</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true"></a><span class="co">#&gt;       0.097       0.008       0.105</span></span></code></pre></div>
<p>As we can see, for N = 1000, the speedup is enormous. There is also an additional “hidden” method to make the <code>anticlustering()</code> function run faster. This method also relies on using fewer exchange partners during the exchange process, but does not use preclustering. This approach is documented here and mostly relies on a dirty “hack” involving the <code>anticlustering()</code> argument <code>categories</code>:</p>
<p>The first step that I am using here is not strictly necessary—in the next section, we will learn more about what this accomplishes—but let’s create the initial clusters before calling <code>anticlustering()</code>. This grouping is the basis on which the exchange procedure starts to improve the anticlustering:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="kw">nrow</span>(iris)</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true"></a>initial_clusters &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>K, N))</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true"></a>initial_clusters</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true"></a><span class="co">#&gt;   [1] 2 2 3 1 3 3 3 3 3 2 1 1 1 3 3 2 1 1 3 1 3 1 1 3 2 1 3 2 2 2 3 2 1 3 2 1 2</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true"></a><span class="co">#&gt;  [38] 3 3 3 2 3 2 1 2 2 1 3 1 1 2 1 1 3 2 2 2 3 2 1 3 3 3 3 1 1 2 1 1 2 1 2 2 1</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true"></a><span class="co">#&gt;  [75] 3 1 1 2 3 3 3 2 1 2 2 3 2 1 3 2 1 2 3 1 1 2 2 1 1 1 3 1 1 2 1 3 3 3 3 3 1</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true"></a><span class="co">#&gt; [112] 3 1 2 2 2 3 2 3 2 2 3 2 3 2 1 2 2 2 1 3 3 3 1 3 1 2 2 1 1 3 3 1 1 2 2 2 1</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true"></a><span class="co">#&gt; [149] 1 3</span></span></code></pre></div>
<p>Now, the argument <code>categories</code> can be used to define which elements serve as exchange partners for each other. Lets create random groups of 10 elements that serve as exchange elements for each other:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true"></a>n_exchange_partners &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true"></a>exchange_partners &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>(N<span class="op">/</span>n_exchange_partners), N))</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true"></a>exchange_partners</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true"></a><span class="co">#&gt;   [1]  5 13  2 11  7  5  6  1  7  3  1  1 15  3 10 10  8  4 14 15 15  7  8  3  2</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true"></a><span class="co">#&gt;  [26] 13  1  9 11  6 13  6  9 13 13  1  9 11 15  7 12  8 12 13 14  7  3 10 12  8</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true"></a><span class="co">#&gt;  [51] 11 11  7  5 15  5  6 14 15  4  9  5 15 12 14  4  4  6 11 10  1  9  6 12  1</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true"></a><span class="co">#&gt;  [76]  8 10 11 14 11 15 14 10  7  2  8  4  8  5 15  3  1  2  4  5 12 12  3  9 13</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true"></a><span class="co">#&gt; [101]  3  8  5 10  1  2  7  9  6 10  1  8 10  5  4  4  9  2  3 14  9  2  5  7 10</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true"></a><span class="co">#&gt; [126] 12 11 13 12  6  9  6 14 14 15 13 13  4  3  4 14 11  2  6  2  3  8  2 12  7</span></span></code></pre></div>
<p>The variable <code>exchange_partners</code> now defines groups of elements that are exchanged with each other. Only elements having the same value in <code>exchange_partners</code> serve as exchange partners for each other. Thus, each element is only swapped with 10 other elements instead of all 150 elements.</p>
<p>Now let’s call anticlustering using the exchange partners we just defined:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(iris[, <span class="dv">-5</span>], <span class="dt">K =</span> initial_clusters))</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true"></a><span class="co">#&gt;       0.007       0.000       0.007</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(iris[, <span class="dv">-5</span>], <span class="dt">K =</span> initial_clusters, <span class="dt">categories =</span> exchange_partners))</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true"></a><span class="co">#&gt;       0.003       0.000       0.003</span></span></code></pre></div>
<p>Well, there is not a lot going on here with this very small data set (N = 150), so let’s do this for a larger data set with 1000 data points.</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true"></a>M &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true"></a>K &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true"></a>data &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(M<span class="op">*</span>N), <span class="dt">ncol =</span> M)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true"></a></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true"></a>initial_clusters &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>K, N))</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true"></a>n_exchange_partners &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true"></a>exchange_partners &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>(N<span class="op">/</span>n_exchange_partners), N))</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true"></a></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> initial_clusters))</span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true"></a><span class="co">#&gt;       3.035       0.008       3.042</span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> initial_clusters, <span class="dt">categories =</span> exchange_partners))</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true"></a><span class="co">#&gt;       0.047       0.008       0.056</span></span></code></pre></div>
<p>The speedup is enormous! Note that this approach even reduces the theoretical run time of the algorithm, because the number of exchanges no longer depends on the size of the input data, but instead is given a fixed value.</p>
</div>
<div id="including-categorical-variables" class="section level3">
<h3>Including categorical variables</h3>
<p>The previous approach to speed up the anticlustering by requiring fewer exchange partners used the <code>categories</code> argument. We should now reflect how this was accomplished, and first note that the <code>categories</code> argument usually has a different purpose: It is used to evenly distribute a categorical variable across groups—we did not care for that in the previous example.</p>
<p>For example, coming back to the iris data set, we may require to evenly distribute the species of the iris plants across 5 groups of plants:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true"></a>groups &lt;-<span class="st"> </span><span class="kw">anticlustering</span>(iris[, <span class="dv">-5</span>], <span class="dt">K =</span> <span class="dv">5</span>, <span class="dt">categories =</span> iris<span class="op">$</span>Species)</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true"></a><span class="kw">table</span>(groups, iris<span class="op">$</span>Species)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true"></a><span class="co">#&gt;       </span></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true"></a><span class="co">#&gt; groups setosa versicolor virginica</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true"></a><span class="co">#&gt;      1     10         10        10</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true"></a><span class="co">#&gt;      2     10         10        10</span></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true"></a><span class="co">#&gt;      3     10         10        10</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true"></a><span class="co">#&gt;      4     10         10        10</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true"></a><span class="co">#&gt;      5     10         10        10</span></span></code></pre></div>
<p>How does the <code>categories</code> argument accomplish the even spread of the species? First, the initial grouping of the elements is not random, but instead a “stratified split”, which ensures that a categorical variable occurs an equal number of times in each split. <code>anticlust</code> has the function <code>categorical_sampling()</code> for this purpose. After conducting the initial stratified split, only plants belonging to the same species serve as exchange partners for each other. This second purpose of the <code>categories</code> argument is the one that we used above to restrict the number of exchange partners to speed up anticlustering: Only elements that have the same value in <code>categories</code> serve as exchange partners for each other.</p>
<p>In the example above, we prevented <code>anticlustering()</code> from conducting a stratified split on the basis of the <code>categories</code> argument because we passed the initial grouping of the variables ourselves. The insight that the <code>categories</code> argument has a twofold purpose—one of which can be shut down by using the <code>K</code> argument as the initial grouping vector—leads to the following approach, where I combine the speedup aspect of <code>categories</code> with the aspect of conducting a stratified split.</p>
<p>First, we conduct a manual stratified split as the initial grouping vector for the <code>K</code> argument in <code>anticlustering()</code>:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true"></a>initial_groups &lt;-<span class="st"> </span><span class="kw">categorical_sampling</span>(iris<span class="op">$</span>Species, <span class="dt">K =</span> <span class="dv">5</span>)</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true"></a><span class="kw">table</span>(initial_groups, iris<span class="op">$</span>Species) <span class="co"># even!</span></span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true"></a><span class="co">#&gt;               </span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true"></a><span class="co">#&gt; initial_groups setosa versicolor virginica</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true"></a><span class="co">#&gt;              1     10         10        10</span></span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true"></a><span class="co">#&gt;              2     10         10        10</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true"></a><span class="co">#&gt;              3     10         10        10</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true"></a><span class="co">#&gt;              4     10         10        10</span></span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true"></a><span class="co">#&gt;              5     10         10        10</span></span></code></pre></div>
<p>Next, as in the previous section, we generate a vector that defines groups of pairwise exchange partners.</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="kw">nrow</span>(iris)</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true"></a>n_exchange_partners &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true"></a>exchange_partners &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>(N<span class="op">/</span>n_exchange_partners), N))</span></code></pre></div>
<p>Now, and this is the crucial part, we pass to the argument <code>categories</code> a matrix that contains both the species as well as the <code>exchange_partners</code> vector, and to the argument <code>K</code> the vector that encodes the stratified split. This way we ensure that:</p>
<ol style="list-style-type: lower-alpha">
<li>the species is split evenly between groups at the start of the algorithm (argument <code>K</code>)</li>
<li>the number of exchange partners is restricted to 10 (one column of the argument <code>categories</code>)</li>
<li>the exchange partners are from the same species, thereby ensuring that the species remains evenly distributed between groups (the other column of <code>categories</code>)</li>
</ol>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true"></a>groups &lt;-<span class="st"> </span><span class="kw">anticlustering</span>(</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true"></a>  iris[, <span class="dv">-5</span>],</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true"></a>  <span class="dt">K =</span> initial_groups, </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true"></a>  <span class="dt">categories =</span> <span class="kw">cbind</span>(iris<span class="op">$</span>Species, exchange_partners)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true"></a>)</span></code></pre></div>
<p>The groups are still balanced after <code>anticlustering()</code> was called:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true"></a><span class="kw">table</span>(groups, iris<span class="op">$</span>Species)</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true"></a><span class="co">#&gt;       </span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true"></a><span class="co">#&gt; groups setosa versicolor virginica</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true"></a><span class="co">#&gt;      1     10         10        10</span></span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true"></a><span class="co">#&gt;      2     10         10        10</span></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true"></a><span class="co">#&gt;      3     10         10        10</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true"></a><span class="co">#&gt;      4     10         10        10</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true"></a><span class="co">#&gt;      5     10         10        10</span></span></code></pre></div>
</div>
</div>
<div id="objective-function" class="section level2">
<h2>Objective function</h2>
<p>The package <code>anticlust</code> primarily implements two objective functions for anticlustering: k-means and the diversity.<a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> The k-means criterion is well-known in cluster analysis and is computed as the sum of the squared Euclidean distances between all data points and the centroid of their respective cluster. The diversity is the overall sum of distances of elements in the same sets (for details, see Papenberg &amp; Klau, 2021). By default, <code>anticlustering()</code> optimizes the “Euclidean diversity”: the diversity objective using the Euclidean distance as measure of pairwise dissimilarity. However, any kind of dissimilarity matrix can be used as input.</p>
<p>As stated above, the anticlustering algorithms recompute the objective function for each attempted exchange. Thus, computing the objective is the major contributor to overall run time. In <code>anticlust</code>, I exploit the fact that anticlustering objectives can be recomputed faster when only two items have swapped between clusters and the objective value prior to the exchange is known. For example, computing the diversity objective “from scratch” is in <span class="math inline">\(O(N^2)\)</span>, but when only two items differ between swaps, it is not necessary to spend the entire <span class="math inline">\(O(N^2)\)</span> time during each exchange. Instead, by “cleverly” updating the objective before and after the swap, the computation reduces to <span class="math inline">\(O(N)\)</span>, leading to about <span class="math inline">\(O(N^3)\)</span> for the entire exchange method (instead of <span class="math inline">\(O(N^4)\)</span>—this is a huge difference). Computing the k-means objective (<code>objective = &quot;variance&quot;</code>) is in <span class="math inline">\(O(M \cdot N)\)</span>, where <span class="math inline">\(M\)</span> is the number of variables. <code>anticlust</code> uses some optimizations during the exchange process to prevent the entire re-computation of the cluster centroids for each exchange, which otherwise consumes most of the run time. However, this does not change the theoretical <span class="math inline">\(O(M \cdot N)\)</span> run time of the computation. Thus, theoretically, re-computing the k-means objective is slower than re-computing the diversity objective. In practice, however, I observe that k-means anticlustering is oftentimes faster than diversity anticlustering. That is, when <span class="math inline">\(N\)</span> is large as compared to <span class="math inline">\(M\)</span> and <span class="math inline">\(K\)</span>. For example, let’s compare running times for k-means and diversity anticlustering for <span class="math inline">\(N = 1000\)</span>, <span class="math inline">\(M = 2\)</span> variables and <span class="math inline">\(K = 5\)</span> groups:</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true"></a>M &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true"></a>K &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true"></a>data &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(M<span class="op">*</span>N), <span class="dt">ncol =</span> M)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true"></a></span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> K, <span class="dt">objective =</span> <span class="st">&quot;diversity&quot;</span>))</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true"></a><span class="co">#&gt;       3.041       0.004       3.046</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> K, <span class="dt">objective =</span> <span class="st">&quot;variance&quot;</span>)) <span class="co"># k-means anticlustering</span></span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true"></a><span class="co">#&gt;       1.762       0.000       1.762</span></span></code></pre></div>
<p>When <span class="math inline">\(M\)</span> and/or <span class="math inline">\(K\)</span> increase, the diversity implementation may be faster, e.g. using <span class="math inline">\(N = 1000\)</span>, <span class="math inline">\(M = 20\)</span> variables and <span class="math inline">\(K = 50\)</span> yields:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true"></a>M &lt;-<span class="st"> </span><span class="dv">20</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true"></a>K &lt;-<span class="st"> </span><span class="dv">50</span></span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true"></a>data &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(M<span class="op">*</span>N), <span class="dt">ncol =</span> M)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> K, <span class="dt">objective =</span> <span class="st">&quot;diversity&quot;</span>))</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true"></a><span class="co">#&gt;       0.205       0.004       0.209</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> K, <span class="dt">objective =</span> <span class="st">&quot;variance&quot;</span>))</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true"></a><span class="co">#&gt;       0.826       0.000       0.827</span></span></code></pre></div>
<p>In most application I am aware of, the k-means method is faster because <span class="math inline">\(M\)</span> and <span class="math inline">\(K\)</span> are usually not very large. However, for example, if we happen to have (approximately) “<span class="math inline">\(M = N\)</span>”, the diversity implementation is much faster because its theoretical run time is better. Note that for very large data sets, however, using the diversity objective may not be feasible at all. The reason for this is that a quadratic matrix of between-item distances has to be computed and stored in memory. It is my experience that on a personal computer this becomes difficult for about &gt; 20000 elements (where the distance matrix has 20000^2 = 400000000 elements). Thus, for large data sets a change of the objective is reasonable; the k-means objective is computationally more efficient and even very large data sets can be processed—at least this is true when the number of variables is (much) smaller than the number of elements. I live in a world where this is usually the case.</p>
<p>Because the k-means objective has some disadvantages for anticlustering (see Papenberg, 2023),<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> you may consider using the k-plus objective, which extends—and effectively re-uses—the k-means criterion. For example, the following code—using <span class="math inline">\(N = 50000\)</span>, 2 features and 2 exchange partners per element—ran in just about 15 seconds on my 10 year old personal computer:</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true"></a></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="dv">50000</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true"></a>M &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true"></a>K &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true"></a>data &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(M<span class="op">*</span>N), <span class="dt">ncol =</span> M)</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true"></a></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true"></a>initial_clusters &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>K, N))</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true"></a>n_exchange_partners &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true"></a>exchange_partners &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>(N<span class="op">/</span>n_exchange_partners), N))</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true"></a></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true"></a><span class="kw">kplus_anticlustering</span>(data, <span class="dt">K =</span> initial_clusters, <span class="dt">categories =</span> exchange_partners)</span></code></pre></div>
<p>My computer crashes when I insert 50000 data points into diversity anticlustering.</p>
</div>
<div id="addendum-fast_anticlustering" class="section level2">
<h2>Addendum: <code>fast_anticlustering()</code></h2>
<p>The <code>anticlust</code> package contains a function called <code>fast_anticlustering()</code>, which (as the name suggests) was introduced to be a faster version of <code>anticlustering()</code> to process large data sets. <code>fast_anticlustering()</code> optimizes the k-means criterion and has an argument <code>k_neighbours</code>, which adjusts the number of exchange partners. Details are found in the documentation (<code>?fast_anticlustering</code>) and in Papenberg and Klau (2021). In my view, the <code>fast_anticlustering()</code> approach to adjusting the number of exchange partners is theoretically and practically more satisfying than the previous “hack” of using the <code>categories</code> argument. However, while the function may still be useful in some settings, I currently do not recommend its use. This is because the exchange algorithm that is called in <code>anticlustering()</code> (and therefore also <code>kplus_anticlustering()</code>, which calls <code>anticlustering()</code>) has been rewritten in C after including <code>fast_anticlustering()</code> in the package. The C implementation is considerably faster as compared to the R implementation in <code>fast_anticlustering()</code>. Due to the way in which exchange partners are generated in <code>fast_anticlustering()</code>, it is also not straight forward use the C implementation of the exchange method in <code>fast_anticlustering()</code>—I would like to change this in the future, but I am not sure when this will happen. So, ironically, <code>fast_anticlustering()</code> is currently not the fastest method for anticlustering, by a long shot:</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true"></a>N &lt;-<span class="st"> </span><span class="dv">1000</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true"></a>M &lt;-<span class="st"> </span><span class="dv">2</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true"></a>K &lt;-<span class="st"> </span><span class="dv">5</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true"></a>data &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(M<span class="op">*</span>N), <span class="dt">ncol =</span> M)</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true"></a></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true"></a>initial_clusters &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>K, N))</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true"></a>n_exchange_partners &lt;-<span class="st"> </span><span class="dv">10</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true"></a>exchange_partners &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="kw">rep_len</span>(<span class="dv">1</span><span class="op">:</span>(N<span class="op">/</span>n_exchange_partners), N))</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true"></a><span class="co"># fast_anticlustering() always optimizes the k-means criterion (i.e., objective = &quot;variance&quot;)</span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">anticlustering</span>(data, <span class="dt">K =</span> initial_clusters, <span class="dt">categories =</span> exchange_partners, <span class="dt">objective =</span> <span class="st">&quot;variance&quot;</span>))</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true"></a><span class="co">#&gt;       0.024       0.000       0.025</span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true"></a><span class="kw">system.time</span>(<span class="kw">fast_anticlustering</span>(data, <span class="dt">K =</span> initial_clusters, <span class="dt">k_neighbours =</span> n_exchange_partners))</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true"></a><span class="co">#&gt;        User      System verstrichen </span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true"></a><span class="co">#&gt;       1.191       0.000       1.192</span></span></code></pre></div>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>Papenberg, M., &amp; Klau, G. W. (2021). Using anticlustering to partition data sets into equivalent parts. <em>Psychological Methods, 26</em>(2), 161–174. <a href="https://doi.org/10.1037/met0000301" class="uri">https://doi.org/10.1037/met0000301</a>.</p>
<p>Papenberg, M. (2023). K-plus Anticlustering: An Improved k-means Criterion for Maximizing Between-Group Similarity. <em>British Journal of Mathematical and Statistical Psychology</em>. Advance online publication. <a href="https://doi.org/10.1111/bmsp.12315" class="uri">https://doi.org/10.1111/bmsp.12315</a></p>
<p>Weitz, R., &amp; Lakshminarayanan, S. (1998). An empirical comparison of heuristic methods for creating maximally diverse groups. <em>Journal of the Operational Research Society, 49</em>(6), 635–646. <a href="https://doi.org/10.1057/palgrave.jors.2600510" class="uri">https://doi.org/10.1057/palgrave.jors.2600510</a></p>
</div>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>Actually, four objectives are natively supported for the <code>anticlustering()</code> argument <code>objective</code>: <code>&quot;diversity&quot;</code>, <code>&quot;variance&quot;</code> (i.e, k-means), <code>&quot;kplus&quot;</code> and <code>&quot;dispersion&quot;</code>. However, the k-plus objective as implemented in <code>anticlust</code> effectively re-uses the original k-means criterion and just extends the input data internally. The dispersion objective has a different goal than the other objectives as it does not strive for between-group similarity, so it cannot be used as an alternative to the other objectives.<a href="#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>The primary disadvantage is that k-means anticlustering only leads to similarity in means, but not in standard deviations or any other distribution aspects; the k-plus criterion can be used to equalize arbitrary distribution moments between groups.<a href="#fnref2" class="footnote-back">↩︎</a></p></li>
</ol>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
